<!doctype html>
<html lang="en">
<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="shortcut icon" type="image/png" href="../img/AK Icon.png" />
    <meta property="og:image" content="../img/AK Icon.png">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="../css/pensive.css">
<!--    style csss-->
    <link rel="stylesheet" href="../css/style.css">
<!--    font awesome cdn-->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <title>AK Blogs</title>
</head>
<body>
<!--navbar -->
<nav class="navbar navbar-expand-lg navbar-light bg-light shadow-sm">
    <a class="navbar-brand" href="..\..\..\my_projects_main_page.html">
        <i class="fa fa-magic" aria-hidden="true"></i>
        AK Blogs</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav ml-auto">
            <li class="nav-item active">
                <a class="nav-link btn btn-primary text-light" href="..\..\..\my_projects_main_page.html">Projects Main Page<span class="sr-only">(current)</span></a>
            </li>
            <!-- <li class="nav-item">
                <a class="nav-link" href="#">Demos</a>
            </li>
            <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    Pages
                </a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                    <a class="dropdown-item" href="#">Action</a>
                    <a class="dropdown-item" href="#">Another action</a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="#">Something else here</a>
                </div>
            </li> -->
            <!-- <li class="nav-item">
                <a class="nav-link" href="..\..\..\Main Page.html" aria-disabled="true">_AK_ Blogs</a>
            </li> -->
            <li class="nav-item">
                <a class="nav-link btn btn-primary text-light" href="..\..\..\..\index.html" aria-disabled="true">Akshayhumar Gunari</a>
            </li>
        </ul>
    </div>
</nav>
<!--end navbar-->

<!--first-section-->
<div class="first-section">
    <div class="container" >
        <div class="row justify-content-center">
            <div class="col-md-9 ">
                <h1 class="h2" style="text-align: center;">Deep Visual Attention Based Transfer Clustering</h1>
                <div class="user d-flex align-items-start justify-content-between bg-light p-4 rounded">
                    <div class="d-flex align-items-start">
                        <img src="../img/AK.JPG" class="img-fluid rounded-circle" alt="">
                        <div class="d-block">
                            <span class="d-block">by <a class="h6" href="..\..\..\..\index.html">Akshayhumar Gunari</a></span>
                            <span class="d-block text-muted">17th October 2020</span>
                        </div>
                    </div>
                    <span class="badge badge-light-primary"><i class="fa fa-heart" aria-hidden="true"></i> 1</span>
                </div>
                <!--//blog section-->
                <div class="blog-section">
                    <img src="./images/Minor Project Logo.png" class="bounce-little img-fluid shadow-sm rounded " alt="">
                    <br><br>
                    <h1 class="h">An Overview of Clustering As Emerging Challenge Of Today's World Of Data</h1>
                    <p class="lead mt-3" style="text-align: justify;">
                        In this article, we propose a methodology to improvise the
                        technique of Deep Transfer Clustering (DTC) to the less variant data
                        distribution. Clustering can be considered the most important unsupervised
                         learning problem. A simple defnition of clustering could be stated
                        as the process of organizing objects into groups whose members are similar 
                        in some way". Image clustering is a crucial but challenging task in
                        machine learning and computer vision. In this paper, we have discussed
                        the clustering of the unlabelled data where the variance between the class
                        is very less. We have discussed the improvement of using attention-based
                        classifers rather than regular classifers as the initial feature extractors
                        in the Deep Transfer Clustering. We have enforced the model to learn
                        only the required region of the interest in the images to get the diferentiable 
                        and robust features that do not take into account the background.
                        This paper is the improvement of the existing Deep Transfer clustering
                        for less variant data distribution.
                    </p>


                    <div class="blockquote-1 bg-light p-4 ">
                        <blockquote class="blockquote">
                            <h4 class="mb-0">Deep Visual Attention Based Transfer Clustering.</h4>
                            <footer class="blockquote-footer">Seventh International Symposium on Computer Vision and the Internet (VisionNet'20). <cite title="Source Title"></cite></footer>
                            <div class="d-flex justify-content-end">
                                <!-- <button class="btn btn-primary"><i ><a class="h6" href="Deep_Visual_Attention_Based_Transfer_Clustering.pdf">View Paper</a></i></button> -->
                                <!-- <button class="btn btn-primary"><i ><a class="h6" href="Deep_Visual_Attention_Based_Transfer_Clustering.pdf">View Paper</a></i></button> -->
                                <div class="button_cont" text-align="center"><a class="example_a" href="Deep_Visual_Attention_Based_Transfer_Clustering.pdf" target="_blank" rel="nofollow noopener">View Paper</a></div>
                                <div class="button_cont" text-align="center"><a class="example_a" href="Deep Visual Attention Based Transfer Clustering Slides.pdf" target="_blank" rel="nofollow noopener">View Slides</a></div>
                            
                            </div>
                        </blockquote>
                    </div>



                    <h2 class="h4">Keywords:</h2>
                    <ul>
                        <li>Deep Embedded Clustering</li>
                        <li>Deep Transfer Clustering</li>
                        <li>Auto Encoders</li>
                        <li>Manual Attention</li>
                        <li>Temporal Ensembling</li>
                        <li>Visual Explanations of CNNs.</li>  
                      </ul>


                    <p>

                        Image clustering is a crucial but challenging task in machine learning and computer vision.
                        Existing methods often ignore the combination between feature learning and clustering.
                        Deep learning algorithms are good at mapping input to output given labeled datasets
                        because of its exceptional capability to express non-linear representations. Because of
                        high capabilities of deep learning algorithms, an attempt is made in the direction to use
                        such supervised models to discover novel object categories in an image collection of
                        crowdsourced data assuming prior knowledge of related but different image classes to
                        reduce the ambiguity of clustering, and improve the quality of the newly discovered classes.
                        
                    </p>
                    <p>The goal of clustering is to determine the internal grouping in a set of unlabeled data. But
                        deciding what constitutes a good clustering is still a challenging problem which varies and
                        depends on various factors, such as complexity of the data, structure of the data etc. It can
                        be shown that there is no absolute “best” criterion which would be independent of the final
                        aim of the clustering. Consequently, it is the user who should supply this criterion, in such
                        a way that the result of the clustering will suit their needs.
                    </p>
                    <h1 class="h2">A Brief Walkthrough</h1>
                    <p style="text-align: justify;">
                        A huge amount of image data is being collected in real world sectors. Image data
                        analytics provides information about important facts and issues of a particular domain. But,
                        it is challenging to handle voluminous, unstructured and unlabeled image collection.
                        Clustering provides groups of homogeneous unlabeled data. Therefore, it is used quite often
                        to access the interesting data easily and quickly. Image clustering is a process of
                        partitioning image data into clusters on the basis of similarities. Whereas, features extracted
                        from images are used for the computation of similarities among them. In this project,
                        significant feature extraction approaches and clustering methods applied on the image data
                        from nine important applicative areas are reviewed. 3D Reconstruction of heritage sites,
                        Medical, 3D imaging, oceanography, industrial automation, remote sensing, mobile
                        phones, security and traffic control are considered applicative areas. Characteristics of
                        images, suitable clustering approaches for each domain, challenges and future research
                        directions for image clustering are discussed.
                    </p>
                    <br>
                    <p style="text-align: justify;">
                        The problem is discovering novel object categories in an image collection. While
                        these images are unlabeled, prior knowledge of related but different image classes is
                        assumed. Such prior knowledge is used to reduce the ambiguity of clustering, and improve
                        the quality of the newly discovered classes. The contributions are demonstrated in three
                        fold. The first contribution is towards designing a deep feature extractor which can extract
                        better differentiable features when trained on intra-class datasets. The second contribution
                        is to extend Deep Embedded Clustering to a transfer learning setting; the algorithm is
                        improved by introducing a representation bottleneck, temporal ensembling, and
                        consistency. The third contribution is a method to estimate the number of classes in the
                        unlabeled data. This also transfers knowledge from the known classes, using them as probes
                        to diagnose different choices for the number of classes in the unlabeled subset.
                        The main focus in the project is to discover novel visual categories in such datasets
                        where there is much ambiguity in clustering the image collection due to very high interclass 
                        similarities. So results are extensively evaluated on such datasets where the images
                        of multiple classes are very similar and are very challenging to cluster the images
                        collection. 
                    </p>




                    <h1 class="h2">Motivation</h1>
                    <p style="text-align: justify;">
                        We assume to have the knowledge of related but different classes of images and use this
                         knowledge to reduce the ambiguity of clustering and improve the quality of new discovered 
                         classes. To design a deep feature extractor, which can actually extract the features which 
                         are differentiable between the classes where the similarity is high. Failure of traditional 
                         clustering techniques like using pre-trained, Deep Embedded Clustering for such datasets 
                         where the classes have very less variance or high similarity.
                    </p>





                    <h1 class="h2">Objectives</h1>
                    <p style="text-align: justify;">
                        Our project objectives are initially to design a tool, which extracts ROI (Region of Interest) in a given image. 
                        To design deep learning-based classifier on inter and intra class containing dataset. To design a deep transfer 
                        clustering on inter and intra class containing dataset. And finally to estimate the number of classes.
                    </p>






                    <h1 class="h2">Related Work</h1>
                    <h1 class = "h4">1. Deep Embedded Clustering.</h1>
                    <img src="./images/DEC.png" class="bounce-little img-fluid shadow-sm rounded " alt="">
                    <p class="text-center small text-muted">Deep Embedded Clustering.</p>
                    <p style="text-align: justify;">
                        Deep Embedded Clustering(DEC) [7] is the algorithm that clusters a set of
                        data points in a jointly optimized feature space. DEC works by iteratively 
                        optimizing a KL divergence based clustering objective with a self-training target
                        distribution. This method can be viewed as an unsupervised extension of semisupervised 
                        self-training. This framework provides a way to learn a representation
                        specialized for clustering without ground truth cluster membership labels. DEC
                        oders improved performance as well as robustness for hyperparameter settings,
                        which is particularly important in unsupervised tasks since cross-validation is
                        not possible.
                    </p>


                    <br>
                    <h1 class = "h4">2. Grad-CAM: Gradient-weighted Class Activation Mapping.</h1>
                    <img src="./images/GRADCAM Block.png" class="bounce-little img-fluid shadow-sm rounded " alt="" style="width: 800px; height: 300px;">
                    <p class="text-center small text-muted">Grad-CAM</p>
                    <p style="text-align: justify;">
                        As shown in the Figure 2.2, using Grad-CAM, we can visually validate where our network is looking, 
                        verifying that it is indeed looking at the correct patterns in the image and activating around those patterns. 
                        If the network is not activating around the proper patterns/objects in the image, then we know:
                    </p>
                    <ul>
                        <li>Our network hasn’t properly learned the underlying patterns in our dataset.</li>
                        <li>Our training procedure needs to be revisited.</li>
                        <li>We may need to collect additional data.</li>
                        <li>And most importantly, our model is not ready for deployment.</li>
                    </ul>
                    <p style="text-align: justify;">Grad-CAM is a tool, which is used to visualize the flow of gradients through a neural network. So that we get to know, what our model is actually learning.</p>





                    <h1 class="h2">Procedural Diagram</h1>



                    <img src="./images/Algorithm 1.png" class="img-fluid bounce-little" alt="" style="width: 1000px; height: 500px;">
                    <p class="text-center small text-muted">Attention Provision For Focused Learning and Feature Extraction.</p>
                    <p style="text-align: justify;">
                        We have designed a tool for data preprocessing, using GrabCut Algorithm. This tool help to get the 
                        ROI(Region Of Interest) in an image. GrabCut is an image segmentation method based on graph cuts. 
                        It takes a user-specified bounding box around the object to be segmented, the algorithm estimates 
                        the color distribution of the target object and that of the background using a Gaussian mixture model.
                    </p>
                    <br>
                    <p style="text-align: justify;">
                        Our methodology is the improvement of Deep Transfer Clustering (DTC)
                        for intra-class clustering. A major step in DTC, i.e., training a classifer that is
                        used as a feature extractor is improvised to get more robust and diferentiable
                        features. As we can see from the Observations section that the classifers are
                        learning some background instead of focusing more on important aspects of the
                        image. This might be good for the classifcation where training and testing classes
                        are the same, but in the case of the clustering of the intra-classes, this might
                        affect the performance of clustering. So instead of providing the raw images for
                        the training of the classifer, images where the background part is removed and
                        only the part of the image which can help the model to focus on the diferentiable
                        features is provided.
                    </p>
                    <br>
                    <p style="text-align: justify;">
                        So, to remove the background from the image, a tool using the GrabCut
                        Algorithm, which can instruct the model to focus on the region of interest for
                        data preprocessing is designed. This tool helps to get the ROI(Region of Interest)
                        in an image. GrabCut is an image segmentation method based on graph cuts.
                        It takes a user-specifed bounding box around the object to be segmented, the
                        algorithm estimates the color distribution of the target object and that of the
                        background using a Gaussian mixture model.
                    </p>


                    <img src="./images/Algorithm 2.png" class="img-fluid bounce-little" alt="">
                    <p class="text-center small text-muted">Deep Attention Visual Based Transfer Clustering.</p>

                    <ul>
                        <li style="text-align: justify;">
                            We train the classifer with the background-subtracted images. Background
                            subtraction is done using the tool which we have created using the grabcut
                            algorithm. Now we have the feature extractor for the upcoming new classes.
                            Though the features may be good for new classes it might not be the best.
                        </li>
                        <li style="text-align: justify;">
                            DTC has improved the DEC algorithm by using Temporal ensembling and
                            consistency constraints , we show that using our method of training the initial 
                            feature extractor by using the manual attention over the training the images
                            gives better results than the regular classifers for the data where there is less
                            variance between the classes, we have changed the initial training process of the
                            DTC, the remaining algorithm remains same as that of DTC.
                        </li>
                        <li style="text-align: justify;">
                            The above figure is the complete algorithm of the Deep Transfer Clustering
                            (DTC), which includes two major steps training of classifer and the fine tuning
                            of the feature extractor model with respect to the cluster assignmnet loss and
                            other constraints, we have changed the first step of the DTC algorithm which is
                            best suitable for the Intra-class clustering.
                        </li>
                    </ul>


                    <h2 class="h4">Experiment Details</h2>
                    <ul>
                        <li>Dataset
                            <ul>
                                <li>Indian Digital Heritage Dataset</li>
                                <li>Imagenet Dog-10</li>
                            </ul>
                        </li>
                        <li>Metric
                            <ul>
                                <li>Algorithm 1
                                    <ul>
                                        <li>Accuracy</li>
                                        <li>Loss</li>
                                    </ul>
                                </li>
                                <li>Algorithm 2
                                    <ul>
                                        <li>Unsupervised Clustering Accuracy - ACC</li>
                                        <li>Normalized Mutual Information - NMI</li>
                                        <li>Adjusted Rand Index - ARI</li>
                                    </ul>
                                </li>
                            </ul>
                        </li>
                        <li>Interference : Extracted features could now be fine tuned to update the clusters in target distribution with increased ACC of ~3.08%.</li>
                    </ul>



                    <h1 class="h4">Results</h1>
                    <p style="text-align: justify;">
                        The results were generated for the dog dataset, the subset of the imagenet
                        dataset. This dataset was chosen because it has very high similarities between
                        the classes and also in many of the dog classes dogs face of one class is somewhat
                        similar to other classes, so we need our classifer to concentrate on the whole dog
                        in the image rather than just concentrating on the face of the dog which is always 
                        true in case of the classifer trained using raw images. Our improvisation
                        was compared with DTC.
                    </p>
                    <p>DTC has three different algorithms namely:</p>
                    <ul>
                        <li>DTC - Baseline: Model is trained using the DEC loss.</li>
                            <img src="./images/Baseline Model.JPG" class="img-fluid bounce-little" alt="" style="width: 400px; height: 250px;">
                            <p class="text-center small text-muted">Baseline Model</p> 
                            <p style="text-align: justify;">The above results were generated for the DTC-Baseline model, where the loss
                                function is just the DEC loss, our results are 3% higher in case of accuracy
                                and NMI and 4% higher in the case of ARI.</p>






                            <li>DTC - PI: Model trained using DEC loss with consistency constraint between
                                predictions of a sample and its transformed counterpart.</li>
                                <img src="./images/PI Model.JPG" class="img-fluid bounce-little" alt="" style="width: 400px; height: 250px;">
                                <p class="text-center small text-muted">PI Model</p> 
                                <p style="text-align: justify;">The above results were generated for the DTC-PI model, where loss func-
                                    tion has the DEC loss and the consistency constraint,our results are slightly
                                    better than the original DTC model's accuracy.</p>




                            <li>DTC - TEP: Model trained using DEC loss with consistency constraint between 
                                the current prediction and temporal ensemble prediction of each sample.</li>
                                <img src="./images/TEP Model.JPG" class="img-fluid bounce-little" alt="" style="width: 400px; height: 250px;">
                                <p class="text-center small text-muted">TEP Model</p> 
                                <p style="text-align: justify;">The above results were generated for the DTC-TEP model, where loss func-
                                    tion consists of DEC loss and consistency constraint, the auxiliary distribu-
                                    tion p(k|i) is calculated using the temporal ensembling method. Our results
                                    are 2.5% higher in the case of accuracy and NMI 4% higher in the case of
                                    ARI.</p>
                    </ul>






                    <h1 class = "h4">Conclusion</h1>


                    <p style="text-align: justify;">
                    Through this project various facts could be concluded, some of them including that the traditional clustering 
                    techniques of using pretrained models for image clustering will not lead to better results for all the kinds of
                    data, especially for those classes where the similarity between the two classes is very high. In such cases where
                    the dataset contains the classes in which it is very difficult to differentiate between the classes. In fact it 
                    is very difficult to extract the differentiable features from the dataset.
                    </p>


                    <p style="text-align: justify;">
                    A simple and effective approach for novel visual category discovery in unlabelled data is introduced, by considering it 
                    as a deep transfer clustering problem. The method proposed can simultaneously learn to extract the features that can 
                    actually differentiate between two classes, learn a data representation and cluster the unlabelled data of novel visual 
                    categories, while leveraging knowledge of related categories in labelled data. The main focus was to cluster the image 
                    collection where the similarity between two classes is very high.
                    </p>

                    <p style="text-align: justify;">
                    Also a novel method to reliably estimate the number of categories in unlabelled data by transferring cluster prior knowledge 
                    using labelled probe data is proposed. We have thoroughly evaluated our method on public benchmarks, and it substantially 
                    outperformed state-of-the-art techniques in both known and unknown category number cases, demonstrating the effectiveness of 
                    our approach for those datasets which are of the ultimate focus for the approach.
 
                    </p>




                    <h1 class="h4">Future Scope</h1>
                    <p style="text-align: justify;">
                    Working with the project titled “Learning to Discover Novel Visual Categories In Crowd Source Data via Deep Transfer Clustering” 
                    opened us up to think about various dimensions which would be considered to work upon in future. The proposed architecture would 
                    be further fine tuned for the IDH Dataset, with appropriate modifications required. The first work to be continued with would be 
                    inducing attention mechanism to design a better feature extractor which can extract the features that are actually differentiable 
                    between the classes. This would be further followed by bringing automatic focused learning which would minimize the efforts that need 
                    to be put in for making the feature extractor learn the intended features from the dataset.
                    Necessary efforts would be planned to work in the dimension of increasing the performance of 
                    feature extractor which will ultimately lead to better clustering for datasets of all kinds.</p>

                    
                    
                </div>
                


                <h1 style="text-align: center;">Thank You</h1>

                <br><br><br>
                <footer role="contentinfo" class="footer">
                    <address style="text-align: center;">
                      Residential Address:<br>
                      Shri Nivas,<br>
                      H.No. 137, Akshay Colony,<br>
                      1st Phase, Gokul Road, <br>
                      Hubli, India, 580-030. <br>
                      </address>
                      
                
                
                  </footer>
                






            </div>
        </div>
    </div>

</div>
<!--end first-section-->

<!--footer-section-->
<div class="py-4 text-center bg-warning mt-5">
    <p class="m-0"> &copy; Copyright by Akshaykumar Gunari, all right reserved.</p>
</div>
<!--end footer section-->

<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
</body>
</html>
